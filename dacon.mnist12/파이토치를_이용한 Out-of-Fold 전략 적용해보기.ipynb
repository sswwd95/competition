{
 "cells": [
  {
   "source": [
    "**주피터 노트북 사용자:**\n",
    "* 노트북에서 실행하실 분들은 `argparse` 삭제하시고 `batch_size`, `lr` 부분을 직접 함수에 인자로 넣으시면 되겠습니다.\n",
    "* 코드 중간 `if __name__ == '__main__':` 은 파이썬에서 C/C++의 메인함수에 해당하는 부분입니다. 노트북에서는 다르게 작동하실 껍니다. 따라서 해당 라인을 삭제하고 함수만 실행시키시면 될겁니다.\n",
    "* 저는 Multi-GPU를 사용하기 때문에 Multi-GPU가 불필요하신 분들은 해당 라인을 삭제하시고, Automatic Mixed Precision은 파이토치 1.5 버전부터 네이티브로 만들어진 기능입니다. 1.5 이하를 사용하시는 분들은 파이토치를 버전업하거나 해당 라인을 수정해서 사용하시기 바랍니다. \n",
    "\n",
    "\n",
    "**추가적인 팁:**\n",
    "* 앙상블, 이미지 어그멘테이션, 스케줄러, 모형 변경 및 커스텀, 커스텀 로스 펑션 등을 순서대로 적용해보면서 자기만의 베이스라인과의 성능 차이를 기록하고 비교해보시기 바랍니다.\n",
    "* `seed`를 고정하지 않았습니다. 병렬처리, 개발환경 등 모든 부분에 따라 다르기 때문에 캐글과 같이 비슷한 환경을 제공하거나 데이터셋이 너무 구려 가중치 초기화를 `seed`로 극복할 경우가 아닌 이상, 잘 학습된 모형의 경우 오차가 그리 크지 않을 겁니다.\n",
    "* **중요: 모형을 커스텀할 때 꼭 레이어 초기화 방법을 설정해주시기 바랍니다. 성능 차이가 매우 큽니다.**\n",
    "* **중요: 사용하실 모형과 딥러닝 프레임워크에 따라 인풋 데이터 형식이 다릅니다. 이미지 경우 채널 순서부터 정규화 방법까지 성능 차이가 매우 크므로 공식 문서를 꼭 읽고 따르시길 바랍니다. `torchvision.models`는 아래에 설명해놨습니다.**\n",
    "* **중요: 코드공유에 공유된 Dacon.Jin님의 TTA를 적용해보시기 바랍니다. 성능 차이가 매우 큽니다.**\n",
    "\n",
    "**참고: 코딩 스타일은 `<PEP8>`을 지킵니다. 파이썬 인덴트는 공백 4칸인데, 데이콘에 노트북 업로드 시 공백이 2칸으로 변경되네요. 4칸으로 수정해서 사용하시기 바랍니다.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from typing import Tuple, Sequence, Callable\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=512, type=int)\n",
    "parser.add_argument('--lr', default=1e-3, type=float)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Out-of-Fold 전략을 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(path: os.PathLike) -> None:\n",
    "    df = pd.read_csv(path)\n",
    "    kfold = KFold(n_splits=5)\n",
    "    for fold, (train, valid) in enumerate(kfold.split(df, df.index)):\n",
    "        df.loc[valid, 'kfold'] = int(fold)\n",
    "\n",
    "    df.to_csv('data/split_kfold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 커스텀 데이터셋 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dir: os.PathLike,\n",
    "        image_ids: os.PathLike,\n",
    "        transforms: Sequence[Callable]\n",
    "    ) -> None:\n",
    "        self.dir = dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.labels = {}\n",
    "        with open(image_ids, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                self.labels[int(row[0])] = list(map(int, row[1:]))\n",
    "\n",
    "        self.image_ids = list(self.labels.keys())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Tensor]:\n",
    "        image_id = self.image_ids[index]\n",
    "        image = Image.open(\n",
    "            os.path.join(self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB')\n",
    "        target = np.array(self.labels.get(image_id)).astype(np.float32)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 이미지 어그멘테이션 정의\n",
    "\n",
    "`torchvision.models`의 모형을 이용하여 transfer learning을 적용하고 싶으실 때 파이토치 공식 지원 `pillow`를 사용하지 않고, `opencv`를 사용하실려면:\n",
    "* 채널 순서는 RGB\n",
    "* `uint8` 0~255 값을 [0, 1] 값으로 정규화\n",
    "* 정규화된 값을 ImageNet의 mean, std로 다시 정규화\n",
    "\n",
    "어그멘테이션 적용 시, 해당 데이터셋의 특징을 잘 파악하고 적용하셔야 합니다. `albumentations`은 `ndarray`로 받습니다. `pillow`를 넘파이로 변경하시기 바랍니다.\n",
    "본 대회의 데이터셋은 1채널이라 3채널로 변경해서 사용하시면 되겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모형 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 26) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = resnet101()\n",
    "        self.classifier = \\\n",
    "            nn.Linear(1000, num_classes)\n",
    "\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold: int, verbose: int = 30) -> None:\n",
    "    split_dataset('data/dirty_mnist_2nd_answer.csv')\n",
    "    df = pd.read_csv('data/split_kfold.csv')\n",
    "    df_train = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "    df_valid = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    df_train.drop(['kfold'], axis=1).to_csv(f'data/train-kfold-{fold}.csv', index=False)\n",
    "    df_valid.drop(['kfold'], axis=1).to_csv(f'data/valid-kfold-{fold}.csv', index=False)\n",
    "\n",
    "    trainset = MnistDataset('data/train', f'data/train-kfold-{fold}.csv', transforms_train)\n",
    "    train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=12)\n",
    "\n",
    "    validset = MnistDataset('data/train', f'data/valid-kfold-{fold}.csv', transforms_test)\n",
    "    valid_loader = DataLoader(validset, batch_size=128, shuffle=False, num_workers=12)\n",
    "\n",
    "    num_epochs = 80\n",
    "    device = 'cuda'\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    model = NetMnistModel().to(device)\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if (i+1) % verbose == 0:\n",
    "                outputs = outputs > 0.0\n",
    "                acc = (outputs == targets).float().mean()\n",
    "                print(f'Fold {fold} | Epoch {epoch} | L: {loss.item():.7f} | A: {acc.item():.7f}')\n",
    "\n",
    "        if epoch > num_epochs-20 and epoch < num_epochs-1:\n",
    "            model.eval()\n",
    "            valid_acc = 0.0\n",
    "            valid_loss = 0.0\n",
    "            valid_size = valid_loader.batch_size\n",
    "            for i, (images, targets) in enumerate(valid_loader):\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                outputs = outputs > 0.0\n",
    "                valid_acc += (outputs == targets).float().mean()\n",
    "\n",
    "            print(f'Fold {fold} | Epoch {epoch} | L: {valid_loss/valid_size:.7f} | A: {valid_acc/valid_size:.7f}\\n')\n",
    "\n",
    "        if epoch > num_epochs-20 and epoch < num_epochs-1:\n",
    "            torch.save(model.state_dict(), f'resnet101-f{fold}-{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(0)\n",
    "    train(1)\n",
    "    train(2)\n",
    "    train(3)\n",
    "    train(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 테스트셋 제출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(fold: int, epoch: int, device: torch.device = 'cuda') -> nn.Module:\n",
    "    model = MnistModel().to(device)\n",
    "    state_dict = {}\n",
    "    for k, v in torch.load(f'resnet-f{fold}-{epoch}.pth').items():\n",
    "        state_dict[k[7:]] = v\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device: torch.device = 'cuda'):\n",
    "    submit = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "    model1 = load_model(0, 50)\n",
    "    model2 = load_model(1, 50)\n",
    "    model3 = load_model(2, 50)\n",
    "    model4 = load_model(3, 50)\n",
    "    model5 = load_model(4, 50)\n",
    "\n",
    "    model1 = nn.DataParallel(model1, device_ids=[0, 1, 2, 3])\n",
    "    model2 = nn.DataParallel(model2, device_ids=[0, 1, 2, 3])\n",
    "    model3 = nn.DataParallel(model3, device_ids=[0, 1, 2, 3])\n",
    "    model4 = nn.DataParallel(model4, device_ids=[0, 1, 2, 3])\n",
    "    model5 = nn.DataParallel(model5, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    model4.eval()\n",
    "    model5.eval()\n",
    "\n",
    "    batch_size = test_loader.batch_size\n",
    "    batch_index = 0\n",
    "    for i, (images, targets) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs1 = model1(images)\n",
    "        outputs2 = model2(images)\n",
    "        outputs3 = model3(images)\n",
    "        outputs4 = model4(images)\n",
    "        outputs5 = model5(images)\n",
    "\n",
    "        outputs = (outputs1 + outputs2 + outputs3 + outputs4 + outputs5) / 5\n",
    "\n",
    "        outputs = outputs > 0.0\n",
    "        batch_index = i * batch_size\n",
    "        submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\n",
    "            outputs.long().squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    submit.to_csv('resnet101-e50-kfold.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}